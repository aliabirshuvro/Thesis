{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "paper [40].ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdtAy-luZexE"
      },
      "source": [
        "  \n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.parameter import Parameter\n",
        "from torch.nn.modules.module import Module\n",
        "import pandas as pd\n",
        "import numpy as np\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6utUcOtkYPE"
      },
      "source": [
        "#Layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVPsB2yRbxUy"
      },
      "source": [
        "class GraphConvolution(Module):\n",
        "    \"\"\"\n",
        "    Simple GCN layer, similar to https://arxiv.org/abs/1609.02907\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_features, out_features, bias=True):\n",
        "        super(GraphConvolution, self).__init__()\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.weight = Parameter(torch.FloatTensor(in_features, out_features))\n",
        "        if bias:\n",
        "            self.bias = Parameter(torch.FloatTensor(out_features))\n",
        "        else:\n",
        "            self.register_parameter('bias', None)\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        stdv = 1. / math.sqrt(self.weight.size(1))\n",
        "        self.weight.data.uniform_(-stdv, stdv)\n",
        "        if self.bias is not None:\n",
        "            self.bias.data.uniform_(-stdv, stdv)\n",
        "\n",
        "    def forward(self, x, adj):\n",
        "        support = torch.mm(x, self.weight)\n",
        "        output = torch.spmm(adj, support)\n",
        "        if self.bias is not None:\n",
        "            return output + self.bias\n",
        "        else:\n",
        "            return output\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + ' (' \\\n",
        "               + str(self.in_features) + ' -> ' \\\n",
        "               + str(self.out_features) + ')'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtdhgNpIkRaD"
      },
      "source": [
        "#GCN Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06RjrEyNbgPj"
      },
      "source": [
        "class GCN(nn.Module):\n",
        "    def __init__(self, nfeat, nhid, nclass, dropout):\n",
        "        super(GCN, self).__init__()\n",
        "\n",
        "        self.gc1 = GraphConvolution(nfeat, nhid)\n",
        "        self.gc2 = GraphConvolution(nhid, nclass)\n",
        "        self.dropout = dropout\n",
        "\n",
        "    def forward(self, x, adj):\n",
        "        x = F.relu(self.gc1(x, adj))\n",
        "        x = F.dropout(x, self.dropout, training=self.training)\n",
        "        x = self.gc2(x, adj)\n",
        "        return F.log_softmax(x, dim=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUpNRTCLkJl7"
      },
      "source": [
        "#One Hot Encoder\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hShr8zc8cJZy"
      },
      "source": [
        "class One_hot_encoder(nn.Module):\n",
        "    def __init__(self, embed_size, time_num=288):\n",
        "        super(One_hot_encoder, self).__init__()\n",
        "        self.time_num = time_num\n",
        "        self.I = nn.Parameter(torch.eye(self.time_num, self.time_num, requires_grad=True))\n",
        "        self.onehot_Linear = nn.Linear(time_num, embed_size)\n",
        "\n",
        "    def forward(self, i, N=25, T=12):\n",
        "    \n",
        "        if i%self.time_num+T > self.time_num :\n",
        "            o1 = self.I[i%self.time_num : , : ]\n",
        "            o2 = self.I[0 : (i+T)%self.time_num, : ]\n",
        "            onehot = torch.cat((o1, o2), 0)\n",
        "        else:        \n",
        "            onehot = self.I[i%self.time_num: i%self.time_num+T, : ]\n",
        "        \n",
        "        #onehot = onehot.repeat(N, 1, 1)   \n",
        "        onehot = onehot.expand(N, T, self.time_num)\n",
        "        onehot = self.onehot_Linear(onehot)\n",
        "        return onehot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRPCYcXpkHCE"
      },
      "source": [
        "#The Transformer Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7m_Q5H-cPc5"
      },
      "source": [
        "class SSelfAttention(nn.Module):\n",
        "    def __init__(self, embed_size, heads):\n",
        "        super(SSelfAttention, self).__init__()\n",
        "        self.embed_size = embed_size\n",
        "        self.heads = heads\n",
        "        self.head_dim = embed_size // heads\n",
        "\n",
        "        assert (\n",
        "            self.head_dim * heads == embed_size\n",
        "        ), \"Embedding size needs to be divisible by heads\"\n",
        "\n",
        "        self.values = nn.Linear(self.head_dim, self.head_dim, bias=False)\n",
        "        self.keys = nn.Linear(self.head_dim, self.head_dim, bias=False)\n",
        "        self.queries = nn.Linear(self.head_dim, self.head_dim, bias=False)\n",
        "        self.fc_out = nn.Linear(heads * self.head_dim, embed_size)\n",
        "\n",
        "    def forward(self, values, keys, query):\n",
        "        # Get number of training examples\n",
        "        N, T, C = query.shape\n",
        "        \n",
        "        # Split the embedding into self.heads different pieces\n",
        "        values = values.reshape(N, T, self.heads, self.head_dim)  #512维拆成heads×head_dim\n",
        "        keys   = keys.reshape(N, T, self.heads, self.head_dim)\n",
        "        query  = query.reshape(N, T, self.heads, self.head_dim)\n",
        "\n",
        "        values  = self.values(values)  # (N, T, heads, head_dim)\n",
        "        keys    = self.keys(keys)      # (N, T, heads, head_dim)\n",
        "        queries = self.queries(query)  # (N, T, heads, heads_dim)\n",
        "\n",
        "        # Einsum does matrix mult. for query*keys for each training example\n",
        "        # with every other training example, don't be confused by einsum\n",
        "        # it's just how I like doing matrix multiplication & bmm\n",
        "\n",
        "        energy = torch.einsum(\"qthd,kthd->qkth\", [queries, keys])#空间self-attention\n",
        "        # queries shape: (N, T, heads, heads_dim),\n",
        "        # keys shape: (N, T, heads, heads_dim)\n",
        "        # energy: (N, N, T, heads)\n",
        "\n",
        "        # Normalize energy values similarly to seq2seq + attention\n",
        "        # so that they sum to 1. Also divide by scaling factor for\n",
        "        # better stability\n",
        "        attention = torch.softmax(energy / (self.embed_size ** (1 / 2)), dim=1)#在K维做softmax，和为1\n",
        "        # attention shape: (N, N, T, heads)\n",
        "\n",
        "        out = torch.einsum(\"qkth,kthd->qthd\", [attention, values]).reshape(\n",
        "            N, T, self.heads * self.head_dim\n",
        "        )        \n",
        "        # attention shape: (N, N, T, heads)\n",
        "        # values shape: (N, T, heads, heads_dim)\n",
        "        # out after matrix multiply: (N, T, heads, head_dim), then\n",
        "        # we reshape and flatten the last two dimensions.\n",
        "\n",
        "        out = self.fc_out(out)\n",
        "        # Linear layer doesn't modify the shape, final shape will be\n",
        "        # (N, T, embed_size)\n",
        "\n",
        "        return out\n",
        "    \n",
        "class TSelfAttention(nn.Module):\n",
        "    def __init__(self, embed_size, heads):\n",
        "        super(TSelfAttention, self).__init__()\n",
        "        self.embed_size = embed_size\n",
        "        self.heads = heads\n",
        "        self.head_dim = embed_size // heads\n",
        "\n",
        "        assert (\n",
        "            self.head_dim * heads == embed_size\n",
        "        ), \"Embedding size needs to be divisible by heads\"\n",
        "\n",
        "        self.values = nn.Linear(self.head_dim, self.head_dim, bias=False)\n",
        "        self.keys = nn.Linear(self.head_dim, self.head_dim, bias=False)\n",
        "        self.queries = nn.Linear(self.head_dim, self.head_dim, bias=False)\n",
        "        self.fc_out = nn.Linear(heads * self.head_dim, embed_size)\n",
        "\n",
        "    def forward(self, values, keys, query):\n",
        "        # Get number of training examples\n",
        "        N, T, C = query.shape\n",
        "\n",
        "        # Split the embedding into self.heads different pieces\n",
        "        values = values.reshape(N, T, self.heads, self.head_dim)  #512维拆成heads×head_dim\n",
        "        keys   = keys.reshape(N, T, self.heads, self.head_dim)\n",
        "        query  = query.reshape(N, T, self.heads, self.head_dim)\n",
        "\n",
        "        values  = self.values(values)  # (N, T, heads, head_dim)\n",
        "        keys    = self.keys(keys)      # (N, T, heads, head_dim)\n",
        "        queries = self.queries(query)  # (N, T, heads, heads_dim)\n",
        "\n",
        "        # Einsum does matrix mult. for query*keys for each training example\n",
        "        # with every other training example, don't be confused by einsum\n",
        "        # it's just how I like doing matrix multiplication & bmm\n",
        "        energy = torch.einsum(\"nqhd,nkhd->nhqk\", [queries, keys])#时间self-attention\n",
        "        # queries shape: (N, T, heads, heads_dim),\n",
        "        # keys shape: (N, T, heads, heads_dim)\n",
        "        # energy: (N, heads, T, T)\n",
        "\n",
        "        # Normalize energy values similarly to seq2seq + attention\n",
        "        # so that they sum to 1. Also divide by scaling factor for\n",
        "        # better stability\n",
        "        attention = torch.softmax(energy / (self.embed_size ** (1 / 2)), dim=3)#在K维做softmax，和为1\n",
        "        # attention shape: (N, heads, query_len, key_len)\n",
        "\n",
        "        out = torch.einsum(\"nhqk,nkhd->nqhd\", [attention, values]).reshape(\n",
        "                N, T, self.heads * self.head_dim\n",
        "        )\n",
        "        # attention shape: (N, heads, T, T)\n",
        "        # values shape: (N, T, heads, heads_dim)\n",
        "        # out after matrix multiply: (N, T, heads, head_dim), then\n",
        "        # we reshape and flatten the last two dimensions.\n",
        "\n",
        "        out = self.fc_out(out)\n",
        "        # Linear layer doesn't modify the shape, final shape will be\n",
        "        # (N, T, embed_size)\n",
        "\n",
        "        return out\n",
        "    \n",
        "    \n",
        "class STransformer(nn.Module):\n",
        "    def __init__(self, embed_size, heads, dropout, forward_expansion):\n",
        "        super(STransformer, self).__init__()\n",
        "        self.attention = SSelfAttention(embed_size, heads)\n",
        "        self.norm1 = nn.LayerNorm(embed_size)\n",
        "        self.norm2 = nn.LayerNorm(embed_size)\n",
        "\n",
        "        self.feed_forward = nn.Sequential(\n",
        "            nn.Linear(embed_size, forward_expansion * embed_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(forward_expansion * embed_size, embed_size),\n",
        "        )\n",
        "        \n",
        "        self.gcn = GCN(embed_size, embed_size, embed_size, dropout)  #调用GCN\n",
        "        self.norm_gcn = nn.InstanceNorm2d(1)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.out1_fc = nn.Linear(embed_size, embed_size)\n",
        "        self.out2_fc = nn.Linear(embed_size, embed_size)\n",
        "\n",
        "    def forward(self, value, key, query, adj):\n",
        "        #Spatial Transformer 部分   \n",
        "        \n",
        "        #adj = adj.unsqueeze(2)\n",
        "        #adj = adj.expand(4, 4, 64)  #拼接邻接矩阵\n",
        "        #query = torch.cat((query, adj), 1)\n",
        "        \n",
        "        attention = self.attention(value, key, query)\n",
        "        # Add skip connection, run through normalization and finally dropout\n",
        "        x = self.dropout(self.norm1(attention + query))\n",
        "        forward = self.feed_forward(x)\n",
        "        out1 = self.dropout(self.norm2(forward + x))\n",
        "        \n",
        "        \n",
        "        # GCN 部分\n",
        "        out2 = torch.Tensor(query.shape[0], 0, query.shape[2])\n",
        "        adj = adj.unsqueeze(0).unsqueeze(0)\n",
        "        adj = self.norm_gcn(adj)\n",
        "        adj = adj.squeeze(0).squeeze(0)\n",
        "        \n",
        "        for t in range(query.shape[1]):\n",
        "            o = self.gcn(query[ : , t,  : ],  adj)\n",
        "            o = o.unsqueeze(1)              # shape [N, T, C]\n",
        "            out2 = torch.cat((out2, o), dim=1)\n",
        "        \n",
        "        \n",
        "        #  融合 STransformer and GCN\n",
        "        g = torch.sigmoid( self.out1_fc(out1) + self.out2_fc(out2) )\n",
        "        out = g*out1 + (1-g)*out2\n",
        "\n",
        "        return out\n",
        "    \n",
        "class TTransformer(nn.Module):\n",
        "    def __init__(self, embed_size, heads, time_num, dropout, forward_expansion):\n",
        "        super(TTransformer, self).__init__()\n",
        "        # Temporal embedding One hot\n",
        "        self.time_num = time_num\n",
        "        self.one_hot = One_hot_encoder(embed_size, time_num)\n",
        "        \n",
        "        \n",
        "        self.attention = TSelfAttention(embed_size, heads)\n",
        "        self.norm1 = nn.LayerNorm(embed_size)\n",
        "        self.norm2 = nn.LayerNorm(embed_size)\n",
        "\n",
        "        self.feed_forward = nn.Sequential(\n",
        "            nn.Linear(embed_size, forward_expansion * embed_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(forward_expansion * embed_size, embed_size),\n",
        "        )\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, value, key, query, i):\n",
        "        \n",
        "        onehot_encoder = self.one_hot(i, N=query.shape[0], T=query.shape[1])      \n",
        "\n",
        "        query = query + onehot_encoder\n",
        "        \n",
        "        attention = self.attention(value, key, query)\n",
        "\n",
        "        # Add skip connection, run through normalization and finally dropout\n",
        "        x = self.dropout(self.norm1(attention + query))\n",
        "        forward = self.feed_forward(x)\n",
        "        out = self.dropout(self.norm2(forward + x))\n",
        "        return out\n",
        "\n",
        "class STTransformerBlock(nn.Module):\n",
        "    def __init__(self, embed_size, heads, time_num, dropout, forward_expansion):\n",
        "        super(STTransformerBlock, self).__init__()\n",
        "        self.STransformer = STransformer(embed_size, heads, dropout, forward_expansion)\n",
        "        self.TTransformer = TTransformer(embed_size, heads, time_num, dropout, forward_expansion)\n",
        "    \n",
        "    def forward(self, value, key, query, adj, i):\n",
        "        x1 = self.STransformer(value, key, query, adj) + query\n",
        "        x2 = self.TTransformer(x1, x1, x1, i) + x1\n",
        "        \n",
        "        return x2\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        embed_size,\n",
        "        num_layers,\n",
        "        heads,\n",
        "        time_num,\n",
        "        device,\n",
        "        forward_expansion,\n",
        "        dropout,\n",
        "    ):\n",
        "\n",
        "        super(Encoder, self).__init__()\n",
        "        self.embed_size = embed_size\n",
        "        self.device = device\n",
        "        self.layers = nn.ModuleList(\n",
        "            [\n",
        "                STTransformerBlock(\n",
        "                    embed_size,\n",
        "                    heads,\n",
        "                    time_num,\n",
        "                    dropout=dropout,\n",
        "                    forward_expansion=forward_expansion\n",
        "                )\n",
        "                for _ in range(num_layers)\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, adj, i):\n",
        "        N, T, C = x.shape\n",
        "        out = self.dropout(x)        \n",
        "\n",
        "        # In the Encoder the query, key, value are all the same, it's in the\n",
        "        # decoder this will change. This might look a bit odd in this case.\n",
        "        for layer in self.layers:\n",
        "            out = layer(out, out, out, adj, i)\n",
        "        return out     \n",
        "    \n",
        "class Transformer(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        embed_size=512,\n",
        "        num_layers=3,\n",
        "        heads=8,\n",
        "        time_num=288,\n",
        "        forward_expansion=4,\n",
        "        dropout=0,\n",
        "        device=\"cpu\",\n",
        "    ):\n",
        "\n",
        "        super(Transformer, self).__init__()\n",
        "        self.encoder = Encoder(\n",
        "            embed_size,\n",
        "            num_layers,\n",
        "            heads,\n",
        "            time_num,\n",
        "            device,\n",
        "            forward_expansion,\n",
        "            dropout,\n",
        "        )\n",
        "\n",
        "        self.device = device\n",
        "\n",
        "    def forward(self, src, adj, i):\n",
        "        enc_src = self.encoder(src, adj, i)\n",
        "        return enc_src\n",
        "\n",
        "\n",
        "class STTransformer(nn.Module):\n",
        "    def __init__(self, \n",
        "                 in_channels = 1, \n",
        "                 embed_size = 512, \n",
        "                 time_num = 288,\n",
        "                 num_layers = 3,\n",
        "                 T_dim = 12,\n",
        "                 output_T_dim = 3,  #第二次卷积输出通道数\n",
        "                 heads = 2,\n",
        "                 ):\n",
        "        \n",
        "        super(STTransformer, self).__init__()\n",
        "        \n",
        "        self.conv1 = nn.Conv2d(in_channels, embed_size, 1)\n",
        "        self.Transformer = Transformer(embed_size, num_layers, heads=heads, time_num=time_num)\n",
        "        self.conv2 = nn.Conv2d(T_dim, output_T_dim, 1)\n",
        "        self.conv3 = nn.Conv2d(embed_size, 1, 1)\n",
        "    \n",
        "    def forward(self, x, adj, i):\n",
        "        # x shape[ C, N, T] \n",
        "        x = x.unsqueeze(0)\n",
        "        input_Transformer = self.conv1(x)        \n",
        "        input_Transformer = input_Transformer.squeeze(0)\n",
        "        input_Transformer = input_Transformer.permute(1, 2, 0)  \n",
        "        \n",
        "        #input_Transformer shape[N, T, C]\n",
        "        output_Transformer = self.Transformer(input_Transformer, adj, i)  \n",
        "       \n",
        "        output_Transformer = output_Transformer.permute(1, 0, 2)\n",
        "        #output_Transformer shape[T, N, C]\n",
        "        \n",
        "        output_Transformer = output_Transformer.unsqueeze(0)     \n",
        "        out = self.conv2(output_Transformer) #out shape: [1, output_T_dim, N, C]\n",
        "        \n",
        "        out = out.permute(0, 3, 2, 1)   #out shape: [1, C, N, output_T_dim]\n",
        "        out = self.conv3( out )         #out shape: [1, 1, N, output_T_dim]\n",
        "       \n",
        "        out = out.squeeze(0).squeeze(0)\n",
        "        \n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3QU8WgOj6M0"
      },
      "source": [
        "#Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXF0XV1Fcapa",
        "outputId": "490745ec-334b-4a94-e16b-c7cc9fa0a947"
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    \n",
        "\n",
        "    days = 10\n",
        "    val_days = 1    \n",
        "    \n",
        "    train_num = 288*days\n",
        "    val_num = 288*val_days\n",
        "    row_num = train_num + val_num\n",
        "\n",
        "    v = pd.read_csv(\"V_25.csv\", nrows = row_num, header= None)\n",
        "    A = pd.read_csv(\"W_25.csv\", header= None)\n",
        "    \n",
        "\n",
        "    A = np.array(A)\n",
        "    A = torch.tensor(A, dtype=torch.float32)\n",
        "       \n",
        "    v = np.array(v)\n",
        "    v = v.T\n",
        "    v = torch.tensor(v, dtype=torch.float32)\n",
        "    \n",
        "    \n",
        "    in_channels=1\n",
        "    embed_size=64\n",
        "    time_num = 288  #1天时间间隔数\n",
        "    num_layers=1\n",
        "    T_dim=12\n",
        "    output_T_dim=3\n",
        "    heads=1\n",
        "    \n",
        "    \n",
        "    model = STTransformer(in_channels, embed_size, time_num, num_layers, T_dim, output_T_dim, heads)   \n",
        "    \n",
        "    #optimizer = torch.optim.SGD(model.parameters(), lr=0.000001)  #小数点后8位\n",
        "    optimizer = torch.optim.RMSprop(model.parameters(), lr=0.001)\n",
        "    criterion = nn.L1Loss()                             #论文要求\n",
        "    \n",
        "    \n",
        "    for i in range(train_num - 15):\n",
        "        x = v[:, i:i+12]\n",
        "        x = x.unsqueeze(0)\n",
        "        y = v[:, i+12:i+15]\n",
        "        \n",
        "        out = model(x, A, i)\n",
        "        loss = criterion(out, y ) \n",
        "        \n",
        "        if i%100 == 0:\n",
        "            #print(\"out\", out)\n",
        "            print(\"MAE loss:\", loss)\n",
        "        \n",
        "        #常规操作\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward() \n",
        "        optimizer.step() \n",
        "        \n",
        "    \n",
        "    #print(\"输出形状\", out.shape)\n",
        "    torch.save(model, \"model.pth\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE loss: tensor(304.6098, grad_fn=<L1LossBackward>)\n",
            "MAE loss: tensor(17.8889, grad_fn=<L1LossBackward>)\n",
            "MAE loss: tensor(24.3126, grad_fn=<L1LossBackward>)\n",
            "MAE loss: tensor(17.1967, grad_fn=<L1LossBackward>)\n",
            "MAE loss: tensor(27.6336, grad_fn=<L1LossBackward>)\n",
            "MAE loss: tensor(16.6425, grad_fn=<L1LossBackward>)\n",
            "MAE loss: tensor(13.2577, grad_fn=<L1LossBackward>)\n",
            "MAE loss: tensor(10.5372, grad_fn=<L1LossBackward>)\n",
            "MAE loss: tensor(25.1338, grad_fn=<L1LossBackward>)\n",
            "MAE loss: tensor(15.0345, grad_fn=<L1LossBackward>)\n",
            "MAE loss: tensor(11.8218, grad_fn=<L1LossBackward>)\n",
            "MAE loss: tensor(12.7452, grad_fn=<L1LossBackward>)\n",
            "MAE loss: tensor(5.2660, grad_fn=<L1LossBackward>)\n",
            "MAE loss: tensor(4.3547, grad_fn=<L1LossBackward>)\n",
            "MAE loss: tensor(4.2555, grad_fn=<L1LossBackward>)\n",
            "MAE loss: tensor(4.9732, grad_fn=<L1LossBackward>)\n",
            "MAE loss: tensor(4.7129, grad_fn=<L1LossBackward>)\n",
            "MAE loss: tensor(3.7163, grad_fn=<L1LossBackward>)\n",
            "MAE loss: tensor(7.2012, grad_fn=<L1LossBackward>)\n",
            "MAE loss: tensor(6.0476, grad_fn=<L1LossBackward>)\n",
            "MAE loss: tensor(7.1101, grad_fn=<L1LossBackward>)\n",
            "MAE loss: tensor(6.2466, grad_fn=<L1LossBackward>)\n",
            "MAE loss: tensor(4.9250, grad_fn=<L1LossBackward>)\n",
            "MAE loss: tensor(3.0255, grad_fn=<L1LossBackward>)\n",
            "MAE loss: tensor(3.0207, grad_fn=<L1LossBackward>)\n",
            "MAE loss: tensor(4.6671, grad_fn=<L1LossBackward>)\n",
            "MAE loss: tensor(13.6927, grad_fn=<L1LossBackward>)\n",
            "MAE loss: tensor(2.2312, grad_fn=<L1LossBackward>)\n",
            "MAE loss: tensor(6.7397, grad_fn=<L1LossBackward>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pOBwftWj3F0"
      },
      "source": [
        "#Validation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZolCCBVjCSD",
        "outputId": "4f2d32b3-a878-44f3-a9c5-fe2693f89116"
      },
      "source": [
        "def MAE(x, y):   #zi自己做MAE\n",
        "    out = torch.abs(x-y)\n",
        "    return out.mean(dim=0)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    \n",
        "    days = 10\n",
        "    val_days = 2    #需要验证天数\n",
        "    train_num = 288*days\n",
        "    val_num = 288*val_days\n",
        "    row_num = train_num + val_num\n",
        "    \n",
        "    v = pd.read_csv(\"V_25.csv\", nrows = row_num, header= None)\n",
        "    A = pd.read_csv(\"W_25.csv\", header= None)\n",
        "\n",
        "    A = np.array(A)\n",
        "    A = torch.tensor(A, dtype=torch.float32)      \n",
        "    v = np.array(v)\n",
        "    v = v.T\n",
        "    v = torch.tensor(v, dtype=torch.float32)\n",
        "    \n",
        "    \n",
        "    in_channels=1\n",
        "    embed_size=64\n",
        "    time_num = 288\n",
        "    num_layers=1\n",
        "    T_dim=12\n",
        "    output_T_dim=3\n",
        "    heads=2\n",
        "       \n",
        "    #model = STTransformer(in_channels, embed_size, time_num, num_layers, T_dim, output_T_dim, heads)      \n",
        "    model = torch.load('model.pth')\n",
        "    criterion1 = nn.L1Loss()   #MAE\n",
        "    criterion3 = nn.MSELoss()  #RMSE\n",
        "    \n",
        "    \n",
        "    for i in range( train_num , row_num-15  ):\n",
        "        x = v[:, i:i+12]\n",
        "        x = x.unsqueeze(0)\n",
        "        y = v[:, i+12:i+15]\n",
        "        \n",
        "        out = model(x, A, i)\n",
        "        \n",
        "        #out=out.T\n",
        "        #y=y.T\n",
        "        \n",
        "        loss1 = criterion1(out, y ) \n",
        "        loss2 = MAE(out, y)\n",
        "        loss3 = torch.sqrt(criterion3(out, y ) )\n",
        "        if i%100 == 0:\n",
        "            #print(\"out\", out)\n",
        "            print(\"MAE  loss\", loss1)\n",
        "            print(\"Loss2:\", loss2)\n",
        "            print(\"RMSE loss\", loss3)\n",
        "        \n",
        "\n",
        "        \n",
        "    \n",
        "    #print(out)\n",
        "    #print(\"输出形状\", out.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE  loss tensor(4.5175, grad_fn=<L1LossBackward>)\n",
            "Loss2: tensor([3.4998, 5.7347, 4.3179], grad_fn=<MeanBackward1>)\n",
            "RMSE loss tensor(5.4760, grad_fn=<SqrtBackward>)\n",
            "MAE  loss tensor(5.3858, grad_fn=<L1LossBackward>)\n",
            "Loss2: tensor([5.0719, 5.7846, 5.3008], grad_fn=<MeanBackward1>)\n",
            "RMSE loss tensor(6.6232, grad_fn=<SqrtBackward>)\n",
            "MAE  loss tensor(5.5716, grad_fn=<L1LossBackward>)\n",
            "Loss2: tensor([4.0212, 5.6590, 7.0348], grad_fn=<MeanBackward1>)\n",
            "RMSE loss tensor(7.5901, grad_fn=<SqrtBackward>)\n",
            "MAE  loss tensor(4.5272, grad_fn=<L1LossBackward>)\n",
            "Loss2: tensor([4.2964, 5.4710, 3.8144], grad_fn=<MeanBackward1>)\n",
            "RMSE loss tensor(5.4494, grad_fn=<SqrtBackward>)\n",
            "MAE  loss tensor(7.0094, grad_fn=<L1LossBackward>)\n",
            "Loss2: tensor([6.2075, 7.6377, 7.1829], grad_fn=<MeanBackward1>)\n",
            "RMSE loss tensor(8.5558, grad_fn=<SqrtBackward>)\n",
            "MAE  loss tensor(6.2470, grad_fn=<L1LossBackward>)\n",
            "Loss2: tensor([5.4611, 7.8182, 5.4617], grad_fn=<MeanBackward1>)\n",
            "RMSE loss tensor(7.1657, grad_fn=<SqrtBackward>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8p3UfmiEd416"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}